---
---
@inproceedings{goswami2025query,
  title={Query Drift Compensation: Enabling Compatibility in Continual Learning of Retrieval Embedding Models},
  author={Goswami, Dipam and Wang, Liying and Twardowski, Bartłomiej and van de Weijer, Joost},
  booktitle={Conference on Lifelong Learning Agents (CoLLAs)},
  arxiv={2506.00037},
  abbr={CoLLAs 2025},
  preview={qdc.png},
  code={https://github.com/dipamgoswami/QDC},
  abstract={Text embedding models enable semantic search, powering several NLP applications like Retrieval Augmented Generation by efficient information retrieval (IR). However, text embedding models are commonly studied in scenarios where the training data is static, thus limiting its applications to dy- namic scenarios where new training data emerges over time. IR methods generally encode a huge corpus of documents to low-dimensional embeddings and store them in a database index. During re- trieval, a semantic search over the corpus is performed and the document whose embedding is most similar to the query embedding is returned. When updating an embedding model with new training data, using the already indexed corpus is suboptimal due to the non-compatibility issue, since the model which was used to obtain the embeddings of the corpus has changed. While re-indexing of old corpus documents using the updated model enables compatibility, it requires much higher com- putation and time. Thus, it is critical to study how the already indexed corpus can still be effectively used without the need of re-indexing. In this work, we establish a continual learning benchmark with large-scale datasets and continually train dense retrieval embedding models on query-document pairs from new datasets in each task and observe forgetting on old tasks due to significant drift of embed- dings. We employ embedding distillation on both query and document embeddings to maintain stability and propose a novel query drift compensation method during retrieval to project new model query embeddings to the old embedding space. This enables compatibility with previously indexed corpus embeddings extracted using the old model and thus reduces the forgetting. We show that the proposed method significantly improves performance without any re-indexing.}
  year={2025},
  selected={true}
}

@inproceedings{goswami2024covariances,
  title={Covariances for Free: Exploiting Mean Distributions for Federated Learning with Pre-Trained Models},
  author={Goswami, Dipam  and Magistri, Simone and Wang, Kai and Twardowski, Bartłomiej and  Bagdanov, Andrew D and Van De Weijer, Joost},
  booktitle={arxiv},
  arxiv={2412.14326},
  abbr={Preprint. Under review.},
  preview={fedcof.png},
  code={https://github.com/dipamgoswami/FedCOF},
  abstract={Using pre-trained models has been found to reduce the effect of data heterogeneity and speed up federated learning algorithms. Recent works have investigated the use of first-order statistics and second-order statistics to aggregate local client data distributions at the server and achieve very high performance without any training. In this work we propose a training-free method based on an unbiased estimator of class covariance matrices. Our method, which only uses first-order statistics in the form of class means communicated by clients to the server, incurs only a fraction of the communication costs required by methods based on communicating second-order statistics. We show how these estimated class covariances can be used to initialize a linear classifier, thus exploiting the covariances without actually sharing them. When compared to state-of-the-art methods which also share only class means, our approach improves performance in the range of 4-26\% with exactly the same communication cost. Moreover, our method achieves performance competitive or superior to sharing second-order statistics with dramatically less communication overhead. Finally, using our method to initialize classifiers and then performing federated fine-tuning yields better and faster convergence.},
  year={2024}
}

@inproceedings{gomezexemplar,
  title={Exemplar-free Continual Representation Learning via Learnable Drift Compensation},
  author={Gomez-Villa, Alex and Goswami, Dipam and Wang, Kai and Bagdanov, Andrew D and Twardowski, Bartlomiej and Van De Weijer, Joost},
  booktitle={European Conference on Computer Vision (ECCV)},
  arxiv={2407.08536},
  abbr={ECCV 2024},
  preview={eccv24.png},
  code={https://github.com/alviur/ldc},
  abstract={Exemplar-free class-incremental learning using a backbone trained from scratch and starting from a small first task presents a significant challenge for continual representation learning. Prototype-based approaches, when continually updated, face the critical issue of semantic drift due to which the old class prototypes drift to different positions in the new feature space. Through an analysis of prototype-based continual learning, we show that forgetting is not due to diminished discriminative power of the feature extractor, and can potentially be corrected by drift compensation. To address this, we propose Learnable Drift Compensation (LDC), which can effectively mitigate drift in any moving backbone, whether supervised or unsupervised. LDC is fast and straightforward to integrate on top of existing continual learning approaches. Furthermore, we showcase how LDC can be applied in combination with self-supervised CL methods, resulting in the first exemplar-free semi-supervised continual learning approach. We achieve state-of-the-art performance in both supervised and semi-supervised settings across multiple datasets.},
  year={2024}
}

@inproceedings{goswami2024calibrating,
  title={Calibrating Higher-Order Statistics for Few-Shot Class-Incremental Learning with Pre-trained Vision Transformers},
  author={Goswami, Dipam and Twardowski, Bart{\l}omiej and Van De Weijer, Joost},
  booktitle={CVPR Workshops - CLVISION},
  abstract={Few-shot class-incremental learning (FSCIL) aims to adapt the model to new classes from very few data (5 samples) without forgetting the previously learned classes. Recent works in many-shot CIL (MSCIL) (using all available training data) exploited pre-trained models to reduce forgetting and achieve better plasticity. In a similar fashion, we use ViT models pre-trained on large-scale datasets for few-shot settings, which face the critical issue of low plasticity. FSCIL methods start with a many-shot first task to learn a very good feature extractor and then move to the few-shot setting from the second task onwards. While the focus of most recent studies is on how to learn the many-shot first task so that the model generalizes to all future few-shot tasks, we explore in this work how to better model the few-shot data using pre-trained models, irrespective of how the first task is trained. Inspired by recent works in MSCIL, we explore how using higher-order feature statistics can influence the classification of few-shot classes. We identify the main challenge of obtaining a good covariance matrix from few-shot data and propose to calibrate the covariance matrix for new classes based on semantic similarity to the many-shot base classes. Using the calibrated feature statistics in combination with existing methods significantly improves few-shot continual classification on several FSCIL benchmarks.},
  abbr={CVPRW 2024},
  arxiv={2404.06622},
  preview={cvprw24.png},
  code={https://github.com/dipamgoswami/FSCIL-Calibration},
  year={2024},
  selected={true}
}

@inproceedings{goswami2024resurrecting,
  title={Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning},
  author={Goswami, Dipam and Soutif-Cormerais, Albin and Liu, Yuyang and Kamath, Sandesh and Twardowski, Bart{\l}omiej and Van De Weijer, Joost},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  abstract={Continual learning methods are known to suffer from catastrophic forgetting, a phenomenon that is particularly hard to counter for methods that do not store exemplars of previous tasks. Therefore, to reduce potential drift in the feature extractor, existing exemplar-free methods are typically evaluated in settings where the first task is significantly larger than subsequent tasks. Their performance drops drastically in more challenging settings starting with a smaller first task. To address this problem of feature drift estimation for exemplar-free methods, we propose to adversarially perturb the current samples such that their embeddings are close to the old class prototypes in the old model embedding space. We then estimate the drift in the embedding space from the old to the new model using the perturbed images and compensate the prototypes accordingly. We exploit the fact that adversarial samples are transferable from the old to the new feature space in a continual learning setting. The generation of these images is simple and computationally cheap. We demonstrate in our experiments that the proposed approach better tracks the movement of prototypes in embedding space and outperforms existing methods on several standard continual learning benchmarks as well as on fine-grained datasets.},
  abbr={CVPR 2024},
  arxiv={2405.19074},
  preview={cvpr24.png},
  code={https://github.com/dipamgoswami/ADC},
  year={2024},
  selected={true}
}

@inproceedings{goswami2023fecam,
  title={Fe{CAM}: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning},
  author={Dipam Goswami and Yuyang Liu and Bart{\l}omiej Twardowski and Joost Van De Weijer},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  abstract={Exemplar-free class-incremental learning (CIL) poses several challenges since it prohibits the rehearsal of data from previous tasks and thus suffers from catastrophic forgetting. Recent approaches to incrementally learning the classifier by freezing the feature extractor after the first task have gained much attention. In this paper, we explore prototypical networks for CIL, which generate new class prototypes using the frozen feature extractor and classify the features based on the Euclidean distance to the prototypes. In an analysis of the feature distributions of classes, we show that classification based on Euclidean metrics is successful for jointly trained features. However, when learning from non-stationary data, we observe that the Euclidean metric is suboptimal and that feature distributions are heterogeneous. To address this challenge, we revisit the anisotropic Mahalanobis distance for CIL. In addition, we empirically show that modeling the feature covariance relations is better than previous attempts at sampling features from normal distributions and training a linear classifier. Unlike existing methods, our approach generalizes to both many- and few-shot CIL settings, as well as to domain-incremental settings. Interestingly, without updating the backbone network, our method obtains state-of-the-art results on several standard continual learning benchmarks.},
  abbr={NeurIPS 2023},
  arxiv={2309.14062},
  preview={neurips23.png},
  code={https://github.com/dipamgoswami/FeCAM},
  year={2023},
  selected={true}
}

@inproceedings{liu2023augmented,
  title={Augmented Box Replay: Overcoming Foreground Shift for Incremental Object Detection},
  author={Liu, Yuyang and Cong, Yang and Goswami, Dipam and Liu, Xialei and Van De Weijer, Joost},
  booktitle={International Conference on Computer Vision (ICCV)},
  abstract={In incremental learning, replaying stored samples from previous tasks together with current task samples is one of the most efficient approaches to address catastrophic forgetting. However, unlike incremental classification, image replay has not been successfully applied to incremental object detection (IOD). In this paper, we identify the overlooked problem of foreground shift as the main reason for this. Foreground shift only occurs when replaying images of previous tasks and refers to the fact that their background might contain foreground objects of the current task. To overcome this problem, a novel and efficient Augmented Box Replay (ABR) method is developed that only stores and replays foreground objects and thereby circumvents the foreground shift problem. In addition, we propose an innovative Attentive RoI Distillation loss that uses spatial attention from region-of-interest (RoI) features to constrain current model to focus on the most important information from old model. ABR significantly reduces forgetting of previous classes while maintaining high plasticity in current classes. Moreover, it considerably reduces the storage requirements when compared to standard image replay. Comprehensive experiments on Pascal-VOC and COCO datasets support the state-of-the-art performance of our model.},
  abbr={ICCV 2023},
  arxiv={2307.12427},
  code={https://github.com/YuyangSunshine/ABR_IOD},
  preview={iccv23.png},
  year={2023}
}

@inproceedings{goswami2023attribution,
  title={Attribution-aware weight transfer: A warm-start initialization for class-incremental semantic segmentation},
  author={Goswami, Dipam and Schuster, Ren{\'e} and Van De Weijer, Joost and Stricker, Didier},
  booktitle={Winter Conference on Applications of Computer Vision (WACV)},
  abstract={In class-incremental semantic segmentation (CISS), deep learning architectures suffer from the critical problems of catastrophic forgetting and semantic background shift. Although recent works focused on these issues, existing classifier initialization methods do not address the background shift problem and assign the same initialization weights to both background and new foreground class classifiers. We propose to address the background shift with a novel classifier initialization method which employs gradient-based attribution to identify the most relevant weights for new classes from the classifier's weights for the previous background and transfers these weights to the new classifier. This warm-start weight initialization provides a general solution applicable to several CISS methods. Furthermore, it accelerates learning of new classes while mitigating forgetting. Our experiments demonstrate significant improvement in mIoU compared to the state-of-the-art CISS methods on the Pascal-VOC 2012, ADE20K and Cityscapes datasets.},
  abbr={WACV 2023},
  arxiv={2210.07207},
  preview={wacv23.png},
  code={https://github.com/dfki-av/AWT-for-CISS},
  year={2023}
}

@inproceedings{aggrawal2023bounding,
  title={Bounding Box Priors for Cell Detection with Point Annotations},
  author={Aggrawal, Hari Om and Goswami, Dipam and Agarwal, Vinti},
  booktitle={IEEE 20th International Symposium on Biomedical Imaging (ISBI)},
  abbr={ISBI 2023},
  abstract={The size of an individual cell type, such as a red blood cell, does not vary much among humans. We use this knowledge as a prior for classifying and detecting cells in images with only a few ground truth bounding box annotations, while most of the cells are annotated with points. This setting leads to weakly semi-supervised learning. We propose replacing points with either stochastic (ST) boxes or bounding box predictions during the training process. The proposed “mean-IOU” ST box maximizes the overlap with all the boxes belonging to the sample space with a class-specific approximated prior probability distribution of bounding boxes. Our method trains with both box- and point-labelled images in conjunction, unlike the existing methods, which train first with box- and then point-labelled images. In the most challenging setting, when only 5% images are box-labelled, quantitative experiments on a urine dataset show that our one-stage method outperforms two-stage methods by 5.56 mAP. Furthermore, we suggest an approach that partially answers “how many box-labelled annotations are necessary?” before training a machine learning model.},
  arxiv={2211.06104},
  preview={isbi23.png},
  code={https://github.com/hariagr/bbox_prior},
  year={2023}
}

@article{shekhawat2021graph,
  title={Graph-based approach for enumerating floorplans based on users specifications},
  author={Shekhawat, Krishnendra and Jain, Rahil N and Bisht, Sumit and Kondaveeti, Aishwarya and Goswami, Dipam},
  journal={AI EDAM, Cambridge University Press},
  abbr={AI EDAM},
  html={https://www.cambridge.org/core/journals/ai-edam/article/abs/graphbased-approach-for-enumerating-floorplans-based-on-users-specifications/C1632000D36BD0D0C1FA9E44584F1F00},
  year={2021},
  preview={floor-plan.png},
  publisher={Cambridge University Press}
}

@article{goswami2021urine,
  title={Urine microscopic image dataset},
  author={Goswami, Dipam and Aggrawal, Hari Om and Gupta, Rajiv and Agarwal, Vinti},
  journal={arXiv},
  abbr={arxiv},
  arxiv={2111.10374},
  preview={cells.jpg},
  code={https://github.com/dipamgoswami/UMID-Urine-Microscopic-Image-Dataset},
  year={2021}
}
